{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "195b0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e4a1a54-9dc7-4a44-9f14-f4265685079d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor(7)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e00f6964-22e8-4ca1-9af3-3ca6a1ed4158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e8a80d9-9df2-42e5-8177-6d6e4110e7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d915d3b-3272-4d52-bd31-a942850392aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6214c99-6e80-46b9-a2c3-db31e33a5dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([1, 2])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb74a268-1805-45b8-8e03-de48168363a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60bdf3e3-ac7b-4082-bb9b-a2f91eb98469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4abad8df-08f8-4f51-8474-e001fbba0f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1,2],[3,4]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "968dd258-29bb-4ba0-844d-723b16be40a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7293c8d0-0fdb-4a94-b4bd-b92dcabd6031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44d0f629-0348-440d-a003-e3506930f27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_tensor = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]]])\n",
    "comp_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c7b9a5b-de39-4a15-a9d5-5ca25cff61af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cac33bbc-9af9-4dfe-b8f7-6e9dad131141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
       "         [0.3904, 0.6009, 0.2566, 0.7936],\n",
       "         [0.9408, 0.1332, 0.9346, 0.5936]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random 3, 4 size tensor\n",
    "\n",
    "torch.manual_seed(42) # this gives same random values everytime\n",
    "\n",
    "tensor_rand = torch.rand((3,4))\n",
    "tensor_rand, tensor_rand.dtype # default dtype is float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "beaa3e26-ed76-414b-8c7b-b350c380f4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.5745, 0.9200, 0.3230],\n",
       "          [0.8613, 0.0919, 0.3102],\n",
       "          [0.9536, 0.6002, 0.0351],\n",
       "          ...,\n",
       "          [0.6501, 0.1374, 0.3852],\n",
       "          [0.7029, 0.0650, 0.1280],\n",
       "          [0.0728, 0.4482, 0.8423]],\n",
       " \n",
       "         [[0.3919, 0.1191, 0.7616],\n",
       "          [0.9423, 0.8760, 0.9324],\n",
       "          [0.3308, 0.0646, 0.4916],\n",
       "          ...,\n",
       "          [0.4601, 0.4145, 0.8877],\n",
       "          [0.7979, 0.1490, 0.8975],\n",
       "          [0.3493, 0.3416, 0.2586]],\n",
       " \n",
       "         [[0.9752, 0.2840, 0.2329],\n",
       "          [0.7765, 0.1522, 0.3084],\n",
       "          [0.0165, 0.2109, 0.1842],\n",
       "          ...,\n",
       "          [0.7706, 0.6538, 0.3952],\n",
       "          [0.1024, 0.6485, 0.3496],\n",
       "          [0.7555, 0.3809, 0.3577]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.8716, 0.6351, 0.7019],\n",
       "          [0.3454, 0.4896, 0.8905],\n",
       "          [0.9717, 0.3601, 0.9916],\n",
       "          ...,\n",
       "          [0.7278, 0.2134, 0.2524],\n",
       "          [0.1369, 0.8770, 0.7452],\n",
       "          [0.5307, 0.9066, 0.6534]],\n",
       " \n",
       "         [[0.2118, 0.8450, 0.1104],\n",
       "          [0.3851, 0.9572, 0.7999],\n",
       "          [0.3918, 0.2505, 0.0856],\n",
       "          ...,\n",
       "          [0.8415, 0.9385, 0.7613],\n",
       "          [0.8405, 0.6385, 0.8038],\n",
       "          [0.0070, 0.9709, 0.6002]],\n",
       " \n",
       "         [[0.5102, 0.6497, 0.7146],\n",
       "          [0.2908, 0.6484, 0.3615],\n",
       "          [0.5139, 0.3529, 0.4334],\n",
       "          ...,\n",
       "          [0.4984, 0.0323, 0.8270],\n",
       "          [0.8660, 0.2001, 0.7926],\n",
       "          [0.1140, 0.6855, 0.0086]]]),\n",
       " 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_rand_big = torch.rand(size=(224, 224, 3), dtype = torch.float32)\n",
    "tensor_rand_big, tensor_rand_big.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1002e265-8d8a-4611-9aca-a651c0c8ef8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32,\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tenor with all zeros and all ones\n",
    "\n",
    "tensor_zeros = torch.zeros(size=(3, 4))\n",
    "tensor_ones = torch.ones(size=(3, 4))\n",
    "tensor_zeros, tensor_zeros.dtype, tensor_ones, tensor_ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d5c7965-4614-4356-b1a8-4d700ddab939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_arange = torch.arange(start=1, end=10, step=1)\n",
    "tensor_arange = torch.arange(start=1, end=10, step=1).reshape(3, 3)\n",
    "tensor_arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "268afab5-03cc-4ae2-8a14-c6dfef411c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]),\n",
       " tensor([[1, 1, 1],\n",
       "         [1, 1, 1],\n",
       "         [1, 1, 1]]),\n",
       " tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_zeros_like = torch.zeros_like(input=tensor_arange) # just takes shape from tensor_arange\n",
    "tensor_ones_like = torch.ones_like(input=tensor_arange)\n",
    "tensor_zeros_like, tensor_ones_like, tensor_arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "682afcd1-9b5d-4f63-8d2b-6051a4dd3372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.], requires_grad=True),\n",
       " torch.Size([3]),\n",
       " device(type='cpu'),\n",
       " None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_value_tensor = torch.tensor([3, 6, 9],\n",
    "                                dtype = torch.float32,\n",
    "                                device = None,\n",
    "                                requires_grad = False)\n",
    "all_value_tensor, all_value_tensor.shape, all_value_tensor.device, all_value_tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bba51bd8-1355-4e53-9e72-dd0acb035438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 3, 4]),\n",
       " tensor([0, 1, 2]),\n",
       " tensor([10, 20, 30]),\n",
       " tensor([0.1000, 0.2000, 0.3000]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add, sub, multi, div\n",
    "tensor_math = torch.tensor([1, 2, 3])\n",
    "tensor_add = tensor_math + 1 # applies to all values\n",
    "tensor_sub = tensor_math - 1\n",
    "tensor_multi = tensor_math * 10\n",
    "tensor_div = tensor_math / 10\n",
    "\n",
    "tensor_add, tensor_sub, tensor_multi, tensor_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0364e443-7961-4312-8b80-d9b2c29779ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
