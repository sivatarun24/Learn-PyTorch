{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725ccc6a-683a-4129-b97e-c40db2a0cb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "# import all necessary things\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23901cb8-d809-41e4-917c-c6e6b01d2766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca78a78d-19ae-4de7-bdd7-21690921b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pizza stack sushi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8babc99f-8ff9-4846-a061-a4861b2c9b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/pizza_steak_sushi already exists\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f'{image_path} already exists')\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\") \n",
    "        zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d481c7d5-ccb5-49c0-8550-2ff9f7e63f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/pizza_steak_sushi/train'),\n",
       " PosixPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62b13fc-5476-4cf9-8c1a-ce7dc2bf6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23cbfd11-eab0-4438-a6e3-da652a581f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9024fff-9f73-4df5-a827-cc703ee56f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset ImageFolder\n",
       "     Number of datapoints: 225\n",
       "     Root location: data/pizza_steak_sushi/train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                RandomHorizontalFlip(p=0.5)\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset ImageFolder\n",
       "     Number of datapoints: 225\n",
       "     Root location: data/pizza_steak_sushi/train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                RandomHorizontalFlip(p=0.5)\n",
       "                ToTensor()\n",
       "            ))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n",
    "test_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n",
    "\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6326d798-2e51-4c36-aedf-18612f2e41c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza', 'steak', 'sushi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = test_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60b84a87-51f5-4b05-b20a-d3c4606c2b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pizza': 0, 'steak': 1, 'sushi': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = test_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b56f045-f564-4d33-96da-f8b68ec8347f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1137, 0.1020, 0.0980,  ..., 0.1255, 0.1216, 0.1176],\n",
       "          [0.1059, 0.0980, 0.0980,  ..., 0.1294, 0.1294, 0.1294],\n",
       "          [0.1020, 0.0980, 0.0941,  ..., 0.1333, 0.1333, 0.1333],\n",
       "          ...,\n",
       "          [0.1098, 0.1098, 0.1255,  ..., 0.1686, 0.1647, 0.1686],\n",
       "          [0.0902, 0.0941, 0.1098,  ..., 0.1686, 0.1647, 0.1686],\n",
       "          [0.0863, 0.0863, 0.0980,  ..., 0.1686, 0.1647, 0.1647]],\n",
       " \n",
       "         [[0.0745, 0.0706, 0.0745,  ..., 0.0588, 0.0588, 0.0588],\n",
       "          [0.0745, 0.0706, 0.0745,  ..., 0.0627, 0.0627, 0.0627],\n",
       "          [0.0706, 0.0745, 0.0745,  ..., 0.0706, 0.0706, 0.0706],\n",
       "          ...,\n",
       "          [0.1255, 0.1333, 0.1373,  ..., 0.2510, 0.2392, 0.2392],\n",
       "          [0.1098, 0.1176, 0.1255,  ..., 0.2510, 0.2392, 0.2314],\n",
       "          [0.1020, 0.1059, 0.1137,  ..., 0.2431, 0.2353, 0.2275]],\n",
       " \n",
       "         [[0.0941, 0.0902, 0.0902,  ..., 0.0157, 0.0196, 0.0196],\n",
       "          [0.0902, 0.0863, 0.0902,  ..., 0.0196, 0.0157, 0.0196],\n",
       "          [0.0902, 0.0902, 0.0902,  ..., 0.0157, 0.0157, 0.0196],\n",
       "          ...,\n",
       "          [0.1294, 0.1333, 0.1490,  ..., 0.1961, 0.1882, 0.1843],\n",
       "          [0.1098, 0.1137, 0.1255,  ..., 0.1922, 0.1843, 0.1804],\n",
       "          [0.1059, 0.0980, 0.1059,  ..., 0.1882, 0.1804, 0.1765]]]),\n",
       " 'pizza')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0][0], train_data[0][1]\n",
    "image, class_names[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab707732-bc3b-4286-9650-24733d4cd042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "batch_size = 32\n",
    "num_workers = os.cpu_count()\n",
    "num_workers, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d97c147-0ba0-4690-8c86-8646dca39ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(dataset=train_data, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(dataset=test_data, shuffle=False, batch_size=batch_size, num_workers=num_workers)\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f9819f2-8a64-4aac-a72e-c1eda1cac205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.2667, 0.2471, 0.2588,  ..., 0.8235, 0.8196, 0.8000],\n",
       "           [0.2549, 0.2510, 0.2510,  ..., 0.8118, 0.7961, 0.7843],\n",
       "           [0.2745, 0.2745, 0.2627,  ..., 0.7961, 0.7882, 0.7922],\n",
       "           ...,\n",
       "           [0.9294, 0.9373, 0.9451,  ..., 0.8118, 0.8078, 0.8118],\n",
       "           [0.9333, 0.9412, 0.9490,  ..., 0.8196, 0.8118, 0.8118],\n",
       "           [0.9255, 0.9373, 0.9451,  ..., 0.8196, 0.8196, 0.8157]],\n",
       " \n",
       "          [[0.1843, 0.1765, 0.1843,  ..., 0.7882, 0.7647, 0.7373],\n",
       "           [0.1765, 0.1725, 0.1686,  ..., 0.7765, 0.7451, 0.7176],\n",
       "           [0.1961, 0.1922, 0.1804,  ..., 0.7647, 0.7529, 0.7490],\n",
       "           ...,\n",
       "           [0.8588, 0.8667, 0.8784,  ..., 0.7294, 0.7255, 0.7373],\n",
       "           [0.8627, 0.8706, 0.8824,  ..., 0.7373, 0.7333, 0.7412],\n",
       "           [0.8588, 0.8706, 0.8824,  ..., 0.7451, 0.7373, 0.7412]],\n",
       " \n",
       "          [[0.0275, 0.0235, 0.0275,  ..., 0.6745, 0.6510, 0.6000],\n",
       "           [0.0235, 0.0235, 0.0196,  ..., 0.6588, 0.5961, 0.5294],\n",
       "           [0.0235, 0.0235, 0.0235,  ..., 0.6275, 0.5882, 0.5608],\n",
       "           ...,\n",
       "           [0.8000, 0.8118, 0.8196,  ..., 0.5804, 0.5882, 0.6196],\n",
       "           [0.8000, 0.8235, 0.8314,  ..., 0.5882, 0.5922, 0.6235],\n",
       "           [0.7922, 0.8078, 0.8235,  ..., 0.5765, 0.6000, 0.6157]]],\n",
       " \n",
       " \n",
       "         [[[0.2196, 0.2039, 0.1294,  ..., 0.0118, 0.0118, 0.0118],\n",
       "           [0.2196, 0.2000, 0.1725,  ..., 0.0118, 0.0118, 0.0078],\n",
       "           [0.1843, 0.1843, 0.2392,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           ...,\n",
       "           [0.8706, 0.8784, 0.8902,  ..., 0.9373, 0.9176, 0.8941],\n",
       "           [0.8627, 0.8745, 0.8824,  ..., 0.9255, 0.9098, 0.8902],\n",
       "           [0.8549, 0.8667, 0.8784,  ..., 0.9098, 0.8941, 0.8824]],\n",
       " \n",
       "          [[0.1882, 0.1765, 0.1137,  ..., 0.0118, 0.0118, 0.0118],\n",
       "           [0.1961, 0.1725, 0.1294,  ..., 0.0118, 0.0118, 0.0078],\n",
       "           [0.1647, 0.1490, 0.1882,  ..., 0.0078, 0.0078, 0.0078],\n",
       "           ...,\n",
       "           [0.8235, 0.8314, 0.8431,  ..., 0.9059, 0.8824, 0.8627],\n",
       "           [0.8235, 0.8314, 0.8431,  ..., 0.8863, 0.8667, 0.8510],\n",
       "           [0.8157, 0.8275, 0.8392,  ..., 0.8706, 0.8588, 0.8510]],\n",
       " \n",
       "          [[0.1882, 0.1765, 0.1176,  ..., 0.0196, 0.0196, 0.0196],\n",
       "           [0.2000, 0.1725, 0.1255,  ..., 0.0196, 0.0196, 0.0157],\n",
       "           [0.1647, 0.1490, 0.1765,  ..., 0.0157, 0.0157, 0.0157],\n",
       "           ...,\n",
       "           [0.8235, 0.8314, 0.8431,  ..., 0.8980, 0.8745, 0.8549],\n",
       "           [0.8196, 0.8314, 0.8392,  ..., 0.8824, 0.8627, 0.8471],\n",
       "           [0.8118, 0.8235, 0.8353,  ..., 0.8667, 0.8510, 0.8431]]],\n",
       " \n",
       " \n",
       "         [[[0.3608, 0.3412, 0.3255,  ..., 0.5961, 0.6863, 0.8078],\n",
       "           [0.4118, 0.3725, 0.3216,  ..., 0.6235, 0.7529, 0.8000],\n",
       "           [0.4706, 0.4980, 0.5647,  ..., 0.6784, 0.7686, 0.7843],\n",
       "           ...,\n",
       "           [0.3412, 0.3451, 0.3333,  ..., 0.3490, 0.3490, 0.3412],\n",
       "           [0.3412, 0.3490, 0.3412,  ..., 0.3529, 0.3647, 0.3569],\n",
       "           [0.3333, 0.3569, 0.3529,  ..., 0.3647, 0.3608, 0.3765]],\n",
       " \n",
       "          [[0.1725, 0.1843, 0.2392,  ..., 0.7020, 0.7725, 0.8627],\n",
       "           [0.2196, 0.2353, 0.2471,  ..., 0.7255, 0.8275, 0.8510],\n",
       "           [0.3569, 0.4157, 0.5137,  ..., 0.7725, 0.8314, 0.8392],\n",
       "           ...,\n",
       "           [0.2549, 0.2784, 0.2784,  ..., 0.1765, 0.1804, 0.1725],\n",
       "           [0.2510, 0.2863, 0.2824,  ..., 0.1765, 0.1843, 0.1765],\n",
       "           [0.2431, 0.2941, 0.2980,  ..., 0.1843, 0.1843, 0.1882]],\n",
       " \n",
       "          [[0.1569, 0.1765, 0.2392,  ..., 0.8078, 0.8863, 0.9922],\n",
       "           [0.2078, 0.2196, 0.2471,  ..., 0.8431, 0.9529, 0.9922],\n",
       "           [0.3725, 0.4314, 0.5647,  ..., 0.8980, 0.9647, 0.9765],\n",
       "           ...,\n",
       "           [0.3255, 0.3686, 0.3882,  ..., 0.1216, 0.1216, 0.1137],\n",
       "           [0.3255, 0.3804, 0.3922,  ..., 0.1216, 0.1216, 0.1176],\n",
       "           [0.3216, 0.3882, 0.4157,  ..., 0.1216, 0.1216, 0.1255]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0.2118, 0.2196, 0.2039,  ..., 0.0902, 0.1686, 0.1882],\n",
       "           [0.1569, 0.1882, 0.2471,  ..., 0.1294, 0.2000, 0.2039],\n",
       "           [0.3098, 0.4000, 0.3843,  ..., 0.2902, 0.3137, 0.2039],\n",
       "           ...,\n",
       "           [0.0627, 0.0510, 0.0392,  ..., 0.3373, 0.3412, 0.3216],\n",
       "           [0.0706, 0.0549, 0.0510,  ..., 0.3176, 0.3020, 0.2706],\n",
       "           [0.0745, 0.0627, 0.0588,  ..., 0.2824, 0.2510, 0.2667]],\n",
       " \n",
       "          [[0.1882, 0.2078, 0.1765,  ..., 0.0863, 0.1490, 0.1843],\n",
       "           [0.1490, 0.1725, 0.2078,  ..., 0.1137, 0.1843, 0.1961],\n",
       "           [0.2353, 0.3176, 0.2980,  ..., 0.2196, 0.2627, 0.1804],\n",
       "           ...,\n",
       "           [0.0588, 0.0471, 0.0353,  ..., 0.3020, 0.2941, 0.2784],\n",
       "           [0.0667, 0.0510, 0.0471,  ..., 0.2784, 0.2667, 0.2392],\n",
       "           [0.0706, 0.0588, 0.0549,  ..., 0.2431, 0.2235, 0.2314]],\n",
       " \n",
       "          [[0.1765, 0.1961, 0.1569,  ..., 0.0980, 0.1529, 0.2000],\n",
       "           [0.1529, 0.1686, 0.1843,  ..., 0.1137, 0.1765, 0.2118],\n",
       "           [0.2000, 0.2353, 0.2157,  ..., 0.1647, 0.2078, 0.1843],\n",
       "           ...,\n",
       "           [0.0431, 0.0392, 0.0275,  ..., 0.2706, 0.2549, 0.2392],\n",
       "           [0.0588, 0.0471, 0.0431,  ..., 0.2431, 0.2431, 0.2157],\n",
       "           [0.0627, 0.0510, 0.0471,  ..., 0.2118, 0.2118, 0.2118]]],\n",
       " \n",
       " \n",
       "         [[[0.0157, 0.0353, 0.2275,  ..., 0.5569, 0.4784, 0.3216],\n",
       "           [0.0157, 0.0157, 0.0667,  ..., 0.5490, 0.5451, 0.5294],\n",
       "           [0.0157, 0.0118, 0.0118,  ..., 0.5176, 0.5373, 0.5333],\n",
       "           ...,\n",
       "           [0.8941, 0.8941, 0.9020,  ..., 0.3098, 0.3373, 0.3765],\n",
       "           [0.8902, 0.8941, 0.9020,  ..., 0.4039, 0.4235, 0.4588],\n",
       "           [0.9216, 0.9020, 0.9020,  ..., 0.4745, 0.4902, 0.4902]],\n",
       " \n",
       "          [[0.0157, 0.0196, 0.1098,  ..., 0.4706, 0.4039, 0.2667],\n",
       "           [0.0118, 0.0157, 0.0353,  ..., 0.4706, 0.4745, 0.4549],\n",
       "           [0.0118, 0.0157, 0.0118,  ..., 0.4471, 0.4627, 0.4667],\n",
       "           ...,\n",
       "           [0.8314, 0.8314, 0.8392,  ..., 0.1255, 0.1490, 0.1765],\n",
       "           [0.8275, 0.8314, 0.8353,  ..., 0.1922, 0.2118, 0.2510],\n",
       "           [0.8588, 0.8353, 0.8275,  ..., 0.2667, 0.2863, 0.3020]],\n",
       " \n",
       "          [[0.0196, 0.0275, 0.1059,  ..., 0.4157, 0.3529, 0.2431],\n",
       "           [0.0275, 0.0275, 0.0353,  ..., 0.4118, 0.4196, 0.4000],\n",
       "           [0.0275, 0.0235, 0.0314,  ..., 0.3804, 0.4078, 0.4000],\n",
       "           ...,\n",
       "           [0.7333, 0.7412, 0.7490,  ..., 0.0863, 0.0941, 0.1098],\n",
       "           [0.7333, 0.7412, 0.7412,  ..., 0.1216, 0.1333, 0.1647],\n",
       "           [0.7686, 0.7412, 0.7373,  ..., 0.1686, 0.1804, 0.2000]]],\n",
       " \n",
       " \n",
       "         [[[0.1451, 0.1490, 0.1451,  ..., 0.3882, 0.3804, 0.3686],\n",
       "           [0.1569, 0.1569, 0.1569,  ..., 0.4078, 0.3961, 0.3765],\n",
       "           [0.1725, 0.2784, 0.4863,  ..., 0.3961, 0.3961, 0.3922],\n",
       "           ...,\n",
       "           [0.3647, 0.3608, 0.3647,  ..., 0.9647, 0.9529, 0.9294],\n",
       "           [0.3725, 0.3686, 0.3647,  ..., 0.9569, 0.9412, 0.8980],\n",
       "           [0.3922, 0.3765, 0.3647,  ..., 0.9412, 0.9137, 0.8745]],\n",
       " \n",
       "          [[0.0824, 0.0784, 0.0667,  ..., 0.1686, 0.1725, 0.1608],\n",
       "           [0.0863, 0.0784, 0.0784,  ..., 0.1843, 0.1804, 0.1608],\n",
       "           [0.1020, 0.1922, 0.3961,  ..., 0.1725, 0.1686, 0.1608],\n",
       "           ...,\n",
       "           [0.2706, 0.2667, 0.2549,  ..., 0.8863, 0.8745, 0.8431],\n",
       "           [0.2824, 0.2784, 0.2667,  ..., 0.8824, 0.8588, 0.8039],\n",
       "           [0.3098, 0.2863, 0.2784,  ..., 0.8627, 0.8275, 0.7804]],\n",
       " \n",
       "          [[0.0706, 0.0784, 0.0745,  ..., 0.1529, 0.1529, 0.1294],\n",
       "           [0.0824, 0.0863, 0.0824,  ..., 0.1451, 0.1451, 0.1373],\n",
       "           [0.0980, 0.1804, 0.3569,  ..., 0.1294, 0.1373, 0.1333],\n",
       "           ...,\n",
       "           [0.2039, 0.2039, 0.2000,  ..., 0.7843, 0.7686, 0.7373],\n",
       "           [0.2000, 0.2039, 0.1922,  ..., 0.7686, 0.7490, 0.7059],\n",
       "           [0.2196, 0.2039, 0.2039,  ..., 0.7569, 0.7216, 0.6745]]]]),\n",
       " tensor([1, 2, 2, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1, 0,\n",
       "         1, 0, 0, 1, 2, 1, 1, 1]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "img, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "599932f7-6927-460d-a040-114f6beff21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49208ec4-20fb-4c2d-8980-7e0be83657b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TingVGG(\n",
       "  (layer_1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer_2): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifer): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TingVGG(nn.Module):\n",
    "    def __init__(self, input_units, hidden_units, output_units):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(input_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*16*16, out_features=output_units)\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        X = self.layer_1(X)\n",
    "        X = self.layer_2(X)\n",
    "        X = self.classifer(X)\n",
    "        return X\n",
    "\n",
    "model_vgg = TingVGG(input_units=3, hidden_units=10, output_units=len(class_names))\n",
    "model_vgg        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "997de33c-50ec-4699-b5eb-28cfe7fa1dcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchinfo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchinfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m summary\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchinfo'"
     ]
    }
   ],
   "source": [
    "# from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f62e3c29-961d-4e53-a022-707ba84136d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /Users/siva_tarun/miniconda3/lib/python3.12/site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a5f0111-ad75-43bb-abc8-6dcff20a9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: nn.Module, train_dataloader: DataLoader, loss_fn: nn.Module, optimizer: torch.optim.Optimizer, accuracy_fn, device: torch.device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            print(f'Model on device: {next(model.parameters()).device}')\n",
    "            print(f'Data on device: {X.device}')\n",
    "            \n",
    "            # X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            curr_train_loss = loss_fn(y_pred, y)\n",
    "            train_loss += curr_train_loss\n",
    "            curr_train_acc = accuracy_fn(y, y_pred)\n",
    "            train_acc += curr_train_acc\n",
    "            optimizer.zero_grad()\n",
    "            curr_train_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_acc /= len(train_dataloader)\n",
    "    \n",
    "        print(f'Epoch: {epoch} | Training Loss: {train_loss} | Testing Accuracy: {train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5248e37-6429-47f2-9a3a-c4bf9b6d1510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: nn.Module, test_dataloader: DataLoader, loss_fn: nn.Module, accuracy_fn, device: torch.device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (X, y) in enumerate(test_dataloader):\n",
    "            # X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            curr_test_loss = loss_fn(y_pred, y)\n",
    "            test_loss += curr_test_loss\n",
    "            curr_test_acc = accuracy_fn(y, y_pred)\n",
    "            test_acc += curr_test_acc\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "        print(f'Testing loss: {test_loss} | Testing accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7aa560c5-fde3-4125-883f-0867155c5efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(L1Loss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.01\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params=model_vgg.parameters(), lr=0.01)\n",
    "\n",
    "loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f37a18c8-4679-4c9c-b808-0d786231cb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on device: cpu\n",
      "Data on device: cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [10, 3, 3, 3], expected input[32, 10, 32, 32] to have 3 channels, but got 10 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_vgg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccuracy_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_step(model\u001b[38;5;241m=\u001b[39mmodel_vgg, test_dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader, loss_fn\u001b[38;5;241m=\u001b[39mloss_fn, accuracy_fn\u001b[38;5;241m=\u001b[39maccuracy_fn)\n",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, train_dataloader, loss_fn, optimizer, accuracy_fn)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData on device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# X, y = X.to(device), y.to(device)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m curr_train_loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     12\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m curr_train_loss\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[16], line 24\u001b[0m, in \u001b[0;36mTingVGG.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     23\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_1(X)\n\u001b[0;32m---> 24\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifer(X)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [10, 3, 3, 3], expected input[32, 10, 32, 32] to have 3 channels, but got 10 channels instead"
     ]
    }
   ],
   "source": [
    "train_step(model=model_vgg, train_dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, accuracy_fn=accuracy_fn, device=device)\n",
    "test_step(model=model_vgg, test_dataloader=test_dataloader, loss_fn=loss_fn, accuracy_fn=accuracy_fn, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f7b5d9b-0269-4663-aed4-dd03f2635d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.7'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, space_eval\n",
    "\n",
    "hyperopt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1c72cd0-1587-4f07-b575-aaf3d4a833ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.rand>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1278017e-0557-493c-b6a9-af1e2876a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar Tensor: 5\n",
      "Array Tensor: tensor([1, 2])\n",
      "Matrix Tensor: tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "3D Tensor: tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [6, 7]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "scalar = torch.tensor(5)\n",
    "print(f'Scalar Tensor: {scalar}')\n",
    "\n",
    "array = torch.tensor([1, 2])\n",
    "print(f'Array Tensor: {array}')\n",
    "\n",
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f'Matrix Tensor: {matrix}')\n",
    "\n",
    "tensor_3d = torch.tensor([[[1,2], [3,4]], [[5,6], [6,7]]])\n",
    "print(f'3D Tensor: {tensor_3d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88493924-59ac-43b2-ae5e-98831fbb0d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Zeros = tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Ones = tensor([[1, 1],\n",
      "        [1, 1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2], [3,4]])\n",
    "print(f'x = {x}')\n",
    "\n",
    "zeros = torch.zeros(3, 4)\n",
    "print(f'Zeros = {zeros}')\n",
    "\n",
    "ones = torch.ones_like(x)\n",
    "print(f'Ones = {ones}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2f8fbe6-5d1a-4ca3-80e8-ed44a4c273ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d90af9c6-ce62-42ec-8744-199ac618c294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5514, 0.7569, 0.8515, 0.4494],\n",
       "         [0.1499, 0.7310, 0.8073, 0.5752],\n",
       "         [0.5673, 0.3957, 0.8606, 0.3150]],\n",
       "\n",
       "        [[0.5670, 0.1624, 0.2676, 0.9685],\n",
       "         [0.8731, 0.3955, 0.7384, 0.7684],\n",
       "         [0.1808, 0.8130, 0.8252, 0.0220]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_torch = torch.rand(2, 3, 4)\n",
    "rand_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6a88f41-b68b-46be-a984-85a19e5cb476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add: tensor([5, 7, 9])\n",
      "Sub: tensor([-3, -3, -3])\n",
      "Multi: tensor([ 4, 10, 18])\n",
      "Div: tensor([0.2500, 0.4000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "print(f'Add: {a + b}')\n",
    "print(f'Sub: {a - b}')\n",
    "print(f'Multi: {a * b}')\n",
    "print(f'Div: {a / b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36f8bcbf-23b5-46b4-8e91-729c7aa2bfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 50,  68],\n",
       "        [122, 167]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "mat2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "matmul = torch.matmul(mat1, mat2.T)\n",
    "matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5ad0883-a8fe-4861-a780-722c7c823f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
      "Reshaped: tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "flattened: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(12)\n",
    "print(f'Tensor: {tensor}')\n",
    "\n",
    "reshaped = tensor.view((3, 4))\n",
    "print(f'Reshaped: {reshaped}')\n",
    "\n",
    "flattened = tensor.view(-1)\n",
    "print(f'flattened: {flattened}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fbcdc9-136e-4fae-8f76-820544a9d9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
